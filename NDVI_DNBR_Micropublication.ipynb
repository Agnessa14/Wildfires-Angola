{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5e17ce-4f50-4430-a447-081b826974cb",
   "metadata": {},
   "source": [
    "# --------- NDVI and DNBR for 2020 fires in Angola --------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3e7bf-bb35-463c-8fc8-7f6ee40d6a6f",
   "metadata": {},
   "source": [
    "# 0. Data acquisition \n",
    "\n",
    "Prior to running this code, the following datasets should be downloaded: \n",
    "\n",
    "1) Globfire (Artés et al., 2019), available here: https://gwis.jrc.ec.europa.eu/apps/country.profile/downloads\n",
    "\n",
    "   *Note: the dataset used here is a subset of the Globfire dataset, created by Brittany Engle, containing only \n",
    "   fires of category F (1000 acres) or greater. This dataset was graciously provided to us by the Climatematch    organizers, saved here: \"~/shared/Data/Projects/Wildfires/ClimateAction_countries.shp\".\n",
    "\n",
    "\n",
    "2) MODIS Surface Reflectance 8-Day product (Vermote, 2021) data (more information here https://lpdaac.usgs.gov/products/mod09a1v061/), available here: https://search.earthdata.nasa.gov/search/granules?p=C2343111356-LPCLOUD!C2343111356-LPCLOUD&pg[1][v]=t&pg[1][dnf]=DAY&pg[1][id]=MOD09A1*h19v09*&pg[1][ecd]=2020-01-01T00%3A00%3A00.000Z%2C2020-12-31T23%3A59%3A59.999Z&pg[1][gsk]=-start_date&pg[1][m]=download&pg[1][cd]=f&fi=MODIS&tl=1704799757!3!! (need to register to have access to data)\n",
    " \n",
    "  - we selected the entire 2020 year and tiles (19,09), (20,09), (19,10) and (20,10), which cover Angola, by searching for filenames \"MOD09A1*h19v09*\", \"MOD09A1*h19v10*\", \"MOD09A1*h20v09*\" \"and MOD09A1*h20v10*\" and all dates in the 2020 year  \n",
    "  - this resulted in 187 .hdf files (46 or 47 per tile)\n",
    "  - these images are saved under ~/shared-public/Jintasaurus_Skip_Energico/modis_images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7eb81-df44-4f65-9047-463ca1bdd50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib\n",
    "from osgeo import gdal\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335e92a-5679-4ad3-9b63-355531cb367e",
   "metadata": {},
   "source": [
    "# 1. Prepare fires (select dates and polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afcb64f-ec30-4402-be31-e88e5bfe8b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code to retrieve and load the data\n",
    "url_climateaction = \"~/shared/Data/Projects/Wildfires/ClimateAction_countries.shp\"\n",
    "Dataset = gpd.read_file(url_climateaction)  # need to update to OSF and pooch.retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9fdbd-b084-46dd-a458-d932bd8f9b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#angola fires - kamil 14.12.2023\n",
    "Dataset[\"IDate\"] = pd.to_datetime(Dataset[\"IDate\"])\n",
    "Dataset[\"FDate\"] = pd.to_datetime(Dataset[\"FDate\"])\n",
    "# Choose country\n",
    "country = \"Angola\"\n",
    "angolaextent =  (9, 26, -21, -4) #lon,lat\n",
    "angolalongitude=slice(9,26)\n",
    "angolalatitudeR=slice(-4,-21) #reversed order for temperature data\n",
    "angolalatitude=slice(-21,-4) \n",
    "\n",
    "# Define the start month (sm) and end month (em) of the dry period (May-September)\n",
    "year = 2020\n",
    "angolaYear = Dataset[(Dataset[\"name\"] == country) &\n",
    "                        (Dataset[\"IDate\"].dt.year == year) & (Dataset[\"FDate\"].dt.year == year)     ]\n",
    "angola_sorted = angolaYear.sort_values(\"Area_Acres\", ascending = False)\n",
    "#angola_sorted #angola_sorted\n",
    "#angolaYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7b167-b673-4c93-9999-4b59aec3ba54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vegetationTypes=['Forest','Shrubs','Herbaceous Vegetation']\n",
    "num_fires = 50\n",
    "# Sample 50 per veg type fires from 2020 and set a seed for reproducibility\n",
    "selectionType = ['Random','Largest']\n",
    "fireselection=selectionType[1] #random or largest?\n",
    "\n",
    "# angolaYear_sample_combined = gpd.GeoDataFrame(columns=angolaYear.columns) #type(angolaYear) - geopandas.geodataframe.GeoDataFrame\n",
    "\n",
    "for vegetation in vegetationTypes:\n",
    "    #the random selection of wildfires\n",
    "    if fireselection=='Random':\n",
    "        angolaYear_vegetation = angolaYear[angolaYear[\"LC_descrip\"] == vegetation]\n",
    "        angolaYear_sample = angolaYear_vegetation.sample(min(500,angolaYear_vegetation.shape[0]), random_state = 42)\n",
    "\n",
    "    #lets try the largest wildfires\n",
    "    if fireselection=='Largest':\n",
    "        angolaYear_vegetation = angola_sorted[angola_sorted[\"LC_descrip\"] == vegetation] #100 largest fires with this vegetation type\n",
    "        angolaYear_sample = angolaYear_vegetation[0:num_fires]\n",
    "        if vegetation == 'Forest':\n",
    "            sample_forest = angolaYear_sample\n",
    "        elif vegetation == 'Shrubs':\n",
    "            sample_shrubs = angolaYear_sample\n",
    "        elif vegetation == 'Herbaceous Vegetation':\n",
    "            sample_herb = angolaYear_sample\n",
    "            \n",
    "    # angolaYear_sample_combined = pd.concat([angolaYear_sample_combined, angolaYear_sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa4fb7-32e5-459e-97ab-de40106d3964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to update min and max from coordinates\n",
    "def update_min_max(coords, lon_min, lon_max, lat_min, lat_max):\n",
    "    #global lon_min, lat_min, lon_max, lat_max\n",
    "    for x, y in coords:\n",
    "        lon_min = min(lon_min, round(x,2))\n",
    "        lat_min = min(lat_min, round(y,2))\n",
    "        lon_max = max(lon_max, round(x,2))\n",
    "        lat_max = max(lat_max, round(y,2))      \n",
    "    return lon_min, lon_max, lat_min, lat_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71304e22-e596-414c-96c3-04db2b90527c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find the fire's size (rectangle with max and min longitude and latitude) from the its geometry polygon\n",
    "def find_fire_rect(FireData):\n",
    "    # Initialize max and min values\n",
    "    lon_min, lat_min= float('inf'), float('inf')\n",
    "    lon_max, lat_max= float('-inf'), float('-inf')\n",
    "    # List to store all coordinates\n",
    "    all_coords = []\n",
    "        \n",
    "    for multipolygon in FireData[\"geometry\"]:\n",
    "        if isinstance(multipolygon, MultiPolygon):\n",
    "            for polygon in multipolygon.geoms: #the geometry can contain Multypolygon\n",
    "                # Update min and max from exterior\n",
    "                lon_min, lon_max, lat_min, lat_max = update_min_max(polygon.exterior.coords, lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "                # Update min and max from interiors\n",
    "                for interior in polygon.interiors: #the geometry can contain just Polygon\n",
    "                    lon_min, lon_max, lat_min, lat_max = update_min_max(interior.coords, lon_min, lon_max, lat_min, lat_max)\n",
    "        elif isinstance(multipolygon, Polygon):\n",
    "            lon_min, lon_max, lat_min, lat_max = update_min_max(multipolygon.exterior.coords, lon_min, lon_max, lat_min, lat_max)\n",
    "                \n",
    "    return {'lon_min': lon_min, 'lon_max': lon_max, 'lat_min':lat_min, 'lat_max':lat_max} # returns Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eab27-8b1e-4ef2-b6dd-34b72821422f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_fire_dates(FireData):\n",
    "    idate = FireData[\"IDate\"]\n",
    "    fdate = FireData[\"FDate\"]\n",
    "\n",
    "    idatestr = idate.dt.strftime('%Y-%m-%d').iloc[0] #day when the fire started \n",
    "    fdatestr = fdate.dt.strftime('%Y-%m-%d').iloc[0] #day when the fire finished \n",
    "\n",
    "    # our precipitation data are samplet just once in a month - the first day of it\n",
    "    idateMstr = idate.dt.strftime('%Y-%m-01').iloc[0] #month (first day of it) when the fire started \n",
    "    fdateMstr = fdate.dt.strftime('%Y-%m-01').iloc[0] #month (first day of it) when the fire finished \n",
    "    return {'idatestr':idatestr,'idateMstr':idateMstr, 'fdatestr':fdatestr, 'fdateMstr':fdateMstr}  # returns Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ec74a-3ac1-4b3e-8675-ab4127cc09dc",
   "metadata": {},
   "source": [
    "# 2. Load images for selected fires (pre and post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07605f7f-9785-41e9-b31f-6a6ab010f6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_date_from_filename(filename):\n",
    "    # Split the filename and extract the part with the date\n",
    "    date_str = filename.split('.')[1]  # 'A2020353' in your example\n",
    "\n",
    "    # Extract the year and the day of the year\n",
    "    year = int(date_str[1:5])  # '2020' in your example\n",
    "    day_of_year = int(date_str[5:])  # '353' in your example\n",
    "\n",
    "    # Convert to a date\n",
    "    date = datetime(year, 1, 1) + timedelta(days=day_of_year - 1)\n",
    "\n",
    "    return date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Example usage\n",
    "filename = 'MOD09A1.A2020001.h19v09.061.2020324110240.hdf'\n",
    "print(extract_date_from_filename(filename))  # Output: '2020-01-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44303f32-0321-436f-8a75-7f9c4629e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nearest_after(items, pivot):\n",
    "    #calculate the diff. for all dates with the \"pivot\" (date of image)\n",
    "    difference_dates = items - pivot\n",
    "    \n",
    "    #convert to int\n",
    "    diff_int = np.array([d.days for d in difference_dates])\n",
    "    \n",
    "    #take only the positive differences, i.e., dates after date of image - rest is 999\n",
    "    diff_int[np.argwhere(diff_int<=0)] = 999\n",
    "    \n",
    "    #take the min, i.e, closest date \n",
    "    closest_date = items[np.argmin(diff_int)]\n",
    "        \n",
    "    return closest_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534088f-41b3-46d5-b192-7919aac5a694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nearest_before(items, pivot):\n",
    "    #calculate the diff. for all dates with the \"pivot\" (date of image)\n",
    "    difference_dates = items - pivot\n",
    "    \n",
    "    #convert to int\n",
    "    diff_int = np.array([d.days for d in difference_dates])\n",
    "    \n",
    "    #take only the negative differences, i.e., dates before date of image - rest is 999\n",
    "    diff_int[np.argwhere(diff_int>=0)] = 999\n",
    "    \n",
    "    #take the min, i.e, closest date \n",
    "    closest_date = items[np.argmin(abs(diff_int))]\n",
    "    \n",
    "    \n",
    "    return closest_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1cc6c-47fe-408b-9a0e-123550c95550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computeNDVI(image_R, image_NIR, mask_R, mask_NIR):\n",
    "    r,c = image_R.shape\n",
    "    ndviOutput = np.zeros((r,c))\n",
    "    for x in range(c):\n",
    "        for y in range(r):\n",
    "            if (image_NIR[y,x] == 0 and image_R[y,x] == 0) or (mask_NIR[y,x] == 1 and mask_R[y,x] == 1):\n",
    "                ndviOutput[y,x] = np.nan\n",
    "            else:\n",
    "                ndviOutput[y,x] = (image_NIR[y,x] - image_R[y,x]) / (image_NIR[y,x] + image_R[y,x])\n",
    "\n",
    "    return ndviOutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0791a91-a234-46ce-88ef-d8e229fc16ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(image):\n",
    "\n",
    "\n",
    "    # Bands 1 (Red), 4 (Green), 3 (Blue), and 2 (Near Infrared) for MOD09A1 RGB\n",
    "    # modis_pre[\"sur_refl_b01\"][0,:,:]  # red\n",
    "    # modis_pre[\"sur_refl_b04\"][0,:,:]  # green\n",
    "    # modis_pre[\"sur_refl_b03\"][0,:,:]  # blue\n",
    "    # modis_pre[\"sur_refl_b02\"][0,:,:]  # Near Infrared (NIR)\n",
    "    # modis_pre[\"sur_refl_b07\"][0,:,:]  # SWIR band\n",
    "\n",
    "    scale_factor = 0.0001\n",
    "    fill_value   = -28672\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # Read data from the specified band and convert it to a NumPy array of float64 data type\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    data_R    = image[\"sur_refl_b01\"][0,:,:] #.ReadAsArray().astype(np.float64)\n",
    "    data_G    = image[\"sur_refl_b04\"][0,:,:]\n",
    "    data_B    = image[\"sur_refl_b03\"][0,:,:]\n",
    "    data_NIR  = image[\"sur_refl_b02\"][0,:,:]\n",
    "    data_SWIR = image[\"sur_refl_b07\"][0,:,:]\n",
    "\n",
    "\n",
    "    # Close the GDAL dataset objects to free up memory\n",
    "    #values, values2 = None, None\n",
    "\n",
    "    #--------------------------------------------------------\n",
    "    # Replace fill values with NaN (Not a Number) in the data\n",
    "    #--------------------------------------------------------\n",
    "    data_R    = np.where(data_R == fill_value,    np.nan, data_R)\n",
    "    data_G    = np.where(data_G == fill_value,    np.nan, data_G)\n",
    "    data_B    = np.where(data_B == fill_value,    np.nan, data_B)\n",
    "    data_NIR  = np.where(data_NIR == fill_value,  np.nan, data_NIR)\n",
    "    data_SWIR = np.where(data_SWIR == fill_value, np.nan, data_SWIR)\n",
    "\n",
    "\n",
    "    #-------------------------\n",
    "    # Multiply by scale factor\n",
    "    #-------------------------\n",
    "    data_R    = data_R    * scale_factor\n",
    "    data_G    = data_G    * scale_factor\n",
    "    data_B    = data_B    * scale_factor\n",
    "    data_NIR  = data_NIR  * scale_factor\n",
    "    data_SWIR = data_SWIR * scale_factor\n",
    "\n",
    "    return data_R, data_NIR, data_SWIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c4e18-08e6-487a-8998-f26598281d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showSCL(image): #view SCL imagery\n",
    "    cmap = matplotlib.colors.ListedColormap(\n",
    "        [\n",
    "            \"black\",\n",
    "            \"red\",\n",
    "            \"chocolate\",\n",
    "            \"brown\",\n",
    "            \"lime\",\n",
    "            \"yellow\",\n",
    "            \"blue\",\n",
    "            \"aqua\",\n",
    "            \"darkgrey\",\n",
    "            \"lightgrey\",\n",
    "            \"deepskyblue\",\n",
    "            \"magenta\",\n",
    "        ]\n",
    "    )\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a7213-e672-46d1-b031-62dc3fde5cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computeSCLMask(image): # compute SCL Mask to 0s and 1s, masking out clouds and bad pixels\n",
    "    rImage, cImage = image.shape\n",
    "    sclOutput = np.zeros((rImage, cImage))\n",
    "    for x in range(cImage):\n",
    "        for y in range(rImage):\n",
    "            sclOutput[y, x] = 1 if image[y, x] in [0, 1, 3, 8, 9, 11] else 0\n",
    "\n",
    "    return sclOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9c6e0-9cf6-4137-8ea9-14c29bc51f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use this code to remap the NDVI to specific colors for values\n",
    "def remapNDVI(NDVI):\n",
    "    remapped = np.zeros((NDVI.shape[0], NDVI.shape[1]))\n",
    "    for x in range(remapped.shape[0]):\n",
    "        for y in range(remapped.shape[1]):\n",
    "            if np.isnan(NDVI[x, y]):\n",
    "                remapped[x, y] = np.nan\n",
    "            elif NDVI[x, y] <= -0.2:\n",
    "                remapped[x, y] = 1\n",
    "            elif NDVI[x, y] <= 0:\n",
    "                remapped[x, y] = 2\n",
    "            elif NDVI[x, y] <= 0.1:\n",
    "                remapped[x, y] = 3\n",
    "            elif NDVI[x, y] <= 0.2:\n",
    "                remapped[x, y] = 4\n",
    "            elif NDVI[x, y] <= 0.3:\n",
    "                remapped[x, y] = 5\n",
    "            elif NDVI[x, y] <= 0.4:\n",
    "                remapped[x, y] = 6\n",
    "            elif NDVI[x, y] <= 0.5:\n",
    "                remapped[x, y] = 7\n",
    "            elif NDVI[x, y] <= 0.6:\n",
    "                remapped[x, y] = 8\n",
    "            elif NDVI[x, y] <= 0.7:\n",
    "                remapped[x, y] = 9\n",
    "            elif NDVI[x, y] <= 0.8:\n",
    "                remapped[x, y] = 10\n",
    "            elif NDVI[x, y] <= 0.9:\n",
    "                remapped[x, y] = 11\n",
    "            elif NDVI[x, y] <= 1:\n",
    "                remapped[x, y] = 12\n",
    "            else:\n",
    "                remapped[x, y] = 13\n",
    "    return remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe79e6-609a-4e6f-a6c3-b3ad879f068f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showNDVI(image): # view remapped NDVI\n",
    "    cmap = matplotlib.colors.ListedColormap(\n",
    "        [\n",
    "            \"#000000\",\n",
    "            \"#a50026\",\n",
    "            \"#d73027\",\n",
    "            \"#f46d43\",\n",
    "            \"#fdae61\",\n",
    "            \"#fee08b\",\n",
    "            \"#ffffbf\",\n",
    "            \"#d9ef8b\",\n",
    "            \"#a6d96a\",\n",
    "            \"#66bd63\",\n",
    "            \"#1a9850\",\n",
    "            \"#006837\",\n",
    "        ]\n",
    "    )\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b6ee7-b299-4efe-83b0-06bd40c038b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_NDVI(image,filename,modis_lon_min_pre,modis_lon_max_pre,modis_lat_min_pre,modis_lat_max_pre): # view remapped NDVI\n",
    "    cmap = matplotlib.colors.ListedColormap(\n",
    "        [\n",
    "            \"#000000\",\n",
    "            \"#a50026\",\n",
    "            \"#d73027\",\n",
    "            \"#f46d43\",\n",
    "            \"#fdae61\",\n",
    "            \"#fee08b\",\n",
    "            \"#ffffbf\",\n",
    "            \"#d9ef8b\",\n",
    "            \"#a6d96a\",\n",
    "            \"#66bd63\",\n",
    "            \"#1a9850\",\n",
    "            \"#006837\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    ax=plt.imshow(image, cmap=cmap, extent=[round(modis_lon_min_pre),round(modis_lon_max_pre),round(modis_lat_min_pre*-1),round(modis_lat_max_pre*-1)], origin='lower')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°S)')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('remapped NDVI (a.u)')\n",
    "    plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f408681-c362-4013-9adc-658c58301292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset-specific functions: NBR and dNBR Code\n",
    "# This code creates the NBR for each image then uses the NBR to create the dNBR. It can easily be updated for other burnt area indices\n",
    "''' Like the previous indices, this code leverages Bands 8 and Bands 12 to calculate the NBR,\n",
    "then it takes the PreNBR and subtracts the PostNBR. By doing so, it removes pixels that had values that were unchanged.\n",
    "After those pixels are removed, the only pixels left are those with values that have changed - ie: the pixels that experienced the fire.\n",
    "How drastic the change between the values of the Pre and Post NBR pixels indicate the severity of the fire'''\n",
    "def computeFireMasks(pre_fire_NIR, pre_fire_SWIR, post_fire_NIR, post_fire_SWIR):\n",
    "\n",
    "    rows, columns = pre_fire_NIR.shape\n",
    "    nbrPost = np.zeros((rows, columns))\n",
    "    nbrPre = np.zeros((rows, columns))\n",
    "    dnbr = np.zeros((rows,columns))\n",
    "\n",
    "    for x in range(columns):\n",
    "        for y in range(rows):\n",
    "            nbrPost[y, x] = (post_fire_NIR[y, x] - post_fire_SWIR[y, x])/(post_fire_NIR[y, x] + post_fire_SWIR[y, x])\n",
    "            nbrPre[y, x] = (pre_fire_NIR[y, x] - pre_fire_SWIR[y, x])/(pre_fire_NIR[y, x] + pre_fire_SWIR[y, x])\n",
    "            dnbr[y, x] = nbrPre[y, x] - nbrPost[y, x]\n",
    "\n",
    "    return dnbr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae05de2-ac5c-4b56-9171-1d4fe0f5e2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remapDNBR(dnbr):\n",
    "    # this code applies a threshold to the dNBR to show the level of burn intensity (unburned, low severity, moderate severity, or high severity)\n",
    "    remapped = np.zeros((dnbr.shape[0], dnbr.shape[1]))\n",
    "    for x in range(remapped.shape[0]):\n",
    "        for y in range(remapped.shape[1]):\n",
    "            if np.isnan(dnbr[x, y]):\n",
    "                remapped[x, y] = np.nan\n",
    "            elif dnbr[x, y] <= -0.251:\n",
    "                remapped[x, y] = 1\n",
    "            elif dnbr[x, y] <= -0.101:\n",
    "                remapped[x, y] = 2\n",
    "            elif dnbr[x, y] <= 0.099:\n",
    "                remapped[x, y] = 3\n",
    "            elif dnbr[x, y] <= 0.269:\n",
    "                remapped[x, y] = 4\n",
    "            elif dnbr[x, y] <= 0.439:\n",
    "                remapped[x, y] = 5\n",
    "            elif dnbr[x, y] <= 0.659:\n",
    "                remapped[x, y] = 6\n",
    "            elif dnbr[x, y] <= 1.3:\n",
    "                remapped[x, y] = 7\n",
    "            else:\n",
    "                remapped[x, y] = 8\n",
    "    return remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494750ba-bca4-4993-ad7f-50b63cadff0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showDNBR(dnbr):\n",
    "    cmap = matplotlib.colors.ListedColormap(\n",
    "        [\n",
    "            \"blue\",\n",
    "            \"teal\",\n",
    "            \"green\",\n",
    "            \"yellow\",\n",
    "            \"orange\",\n",
    "            \"red\",\n",
    "            \"purple\",\n",
    "        ]\n",
    "    )\n",
    "    plt.imshow(remapDNBR(dnbr), cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df41690-aa81-4e6c-a880-b3ef21437a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_DNBR(dnbr,filename,modis_lon_min_pre,modis_lon_max_pre,modis_lat_min_pre,modis_lat_max_pre):\n",
    "    cmap = matplotlib.colors.ListedColormap(\n",
    "        [\n",
    "            \"blue\",\n",
    "            \"teal\",\n",
    "            \"green\",\n",
    "            \"yellow\",\n",
    "            \"orange\",\n",
    "            \"red\",\n",
    "            \"purple\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ax=plt.imshow(remapDNBR(dnbr), cmap=cmap, extent=[round(modis_lon_min_pre),round(modis_lon_max_pre),round(modis_lat_min_pre*-1),round(modis_lat_max_pre*-1)], origin='lower')\n",
    "    plt.xlabel('Longitude (°E)')\n",
    "    plt.ylabel('Latitude (°S)')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('remapped dNBR (a.u)')\n",
    "    \n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a1a20-de8c-434e-bfce-94dc593bca6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_modis_latitude_longitude(modis_dataset):\n",
    "\n",
    "    num_rows = len(modis_dataset.y)\n",
    "    num_columns = len(modis_dataset.x)\n",
    "\n",
    "    modis_lat = modis_dataset.attrs[\"GRINGPOINTLATITUDE.1\"].split(',')\n",
    "    modis_lon = modis_dataset.attrs[\"GRINGPOINTLONGITUDE.1\"].split(',')\n",
    "\n",
    "    modis_lat_west_jump = (float(modis_lat[1]) - float(modis_lat[0]))/num_rows #rows\n",
    "    modis_lat_east_jump = (float(modis_lat[2]) - float(modis_lat[3]))/num_rows\n",
    "    modis_lat_jump = np.mean([modis_lat_west_jump, modis_lat_east_jump])\n",
    "\n",
    "    modis_lon_north_jump = (float(modis_lon[2]) - float(modis_lon[1]))/num_columns #columns\n",
    "    modis_lon_south_jump = (float(modis_lon[3]) - float(modis_lon[0]))/num_columns #columns\n",
    "    modis_lon_jump = np.mean([modis_lon_north_jump, modis_lon_south_jump])\n",
    "\n",
    "    modis_min_lon = np.mean([float(modis_lon[0]),float(modis_lon[1])])\n",
    "    modis_max_lon = np.mean([float(modis_lon[2]),float(modis_lon[3])])\n",
    "    modis_min_lat = np.mean([float(modis_lat[0]),float(modis_lat[3])])\n",
    "    modis_max_lat = np.mean([float(modis_lat[1]),float(modis_lat[2])])\n",
    "    \n",
    "    return modis_min_lon, modis_max_lon, modis_min_lat, modis_max_lat, modis_lon_jump, modis_lat_jump\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89270d-5e26-4ff8-b6cf-9d16aabc7157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fire_rect_indices(modis_lon_min,modis_lon_jump,modis_lat_max,modis_lat_jump,rect):\n",
    "    \n",
    "    index_lon_min = round((rect[\"lon_min\"] - modis_lon_min)/modis_lon_jump)\n",
    "    index_lon_max = round((rect[\"lon_max\"] - modis_lon_min)/modis_lon_jump)\n",
    "    index_lat_min = abs(round((rect[\"lat_min\"] - modis_lat_max)/modis_lat_jump)) #abs because lat is negative\n",
    "    index_lat_max = abs(round((rect[\"lat_max\"] - modis_lat_max)/modis_lat_jump)) \n",
    "    \n",
    "    return index_lon_min, index_lon_max, index_lat_min, index_lat_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc55ce3-5e53-4a20-bf72-d5e51c8fe157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the Modis dates\n",
    "dates_modis_19_09 = []\n",
    "dates_modis_datetime_19_09 = []\n",
    "all_filenames_19_09 = []\n",
    "\n",
    "dates_modis_19_10 = []\n",
    "dates_modis_datetime_19_10 = []\n",
    "all_filenames_19_10 = []\n",
    "\n",
    "dates_modis_20_09 = []\n",
    "dates_modis_datetime_20_09 = []\n",
    "all_filenames_20_09 = []\n",
    "\n",
    "dates_modis_20_10 = []\n",
    "dates_modis_datetime_20_10 = []\n",
    "all_filenames_20_10 = []\n",
    "\n",
    "modis_dir=os.path.expanduser(\"~/shared-public/Jintasaurus_Skip_Energico/modis_images/\")\n",
    "\n",
    "for filename in os.listdir(modis_dir):\n",
    "    if \".hdf\" in filename and \"h19v09\" in filename:\n",
    "        date_filename = extract_date_from_filename(filename)\n",
    "        d_datetime = datetime.strptime(date_filename, \"%Y-%m-%d\").date()\n",
    "        dates_modis_19_09.append(date_filename)\n",
    "        dates_modis_datetime_19_09.append(d_datetime)\n",
    "        all_filenames_19_09.append(os.path.join(modis_dir, filename))\n",
    "    \n",
    "    elif \".hdf\" in filename and \"h19v10\" in filename:\n",
    "        date_filename = extract_date_from_filename(filename)\n",
    "        d_datetime = datetime.strptime(date_filename, \"%Y-%m-%d\").date()\n",
    "        dates_modis_19_10.append(date_filename)\n",
    "        dates_modis_datetime_19_10.append(d_datetime)\n",
    "        all_filenames_19_10.append(os.path.join(modis_dir, filename))\n",
    "        \n",
    "    elif \".hdf\" in filename and \"h20v09\" in filename:\n",
    "        date_filename = extract_date_from_filename(filename)\n",
    "        d_datetime = datetime.strptime(date_filename, \"%Y-%m-%d\").date()\n",
    "        dates_modis_20_09.append(date_filename)\n",
    "        dates_modis_datetime_20_09.append(d_datetime)\n",
    "        all_filenames_20_09.append(os.path.join(modis_dir, filename))\n",
    "    \n",
    "    elif \".hdf\" in filename and \"h20v10\" in filename:\n",
    "        date_filename = extract_date_from_filename(filename)\n",
    "        d_datetime = datetime.strptime(date_filename, \"%Y-%m-%d\").date()\n",
    "        dates_modis_20_10.append(date_filename)\n",
    "        dates_modis_datetime_20_10.append(d_datetime)\n",
    "        all_filenames_20_10.append(os.path.join(modis_dir, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b079a-31e0-4b40-95af-570d1a85b3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_fire_index = 1\n",
    "\n",
    "for vegetation in vegetationTypes:\n",
    "    \n",
    "    ndvi_pre_remapped = []\n",
    "    ndvi_post_remapped = []\n",
    "    dndvi_remapped = []\n",
    "    dnbr_remapped = [] \n",
    "    ndvi_pre_og = []\n",
    "    dnbr_og = []\n",
    "\n",
    "    for j in range(num_fires):\n",
    "        if vegetation == 'Forest':\n",
    "            OneFire = sample_forest[j:j+1]\n",
    "        elif vegetation == 'Shrubs':\n",
    "            OneFire = sample_shrubs[j:j+1]\n",
    "        if vegetation == 'Herbaceous Vegetation':\n",
    "            OneFire = sample_herb[j:j+1]\n",
    "            \n",
    "        print(vegetation)\n",
    "        firedate = find_fire_dates(OneFire)\n",
    "        rect = find_fire_rect(OneFire)  \n",
    "        \n",
    "        #select tile\n",
    "        if rect['lat_min'] > -10 and rect['lon_max'] < 20:\n",
    "            dates_modis = np.array(dates_modis_19_09)\n",
    "            dates_modis_dt = np.array(dates_modis_datetime_19_09)\n",
    "            all_filenames = all_filenames_19_09\n",
    "        elif rect['lat_min'] > -10 and rect['lon_max'] > 20:\n",
    "            dates_modis = np.array(dates_modis_20_09)\n",
    "            dates_modis_dt = np.array(dates_modis_datetime_20_09)\n",
    "            all_filenames = all_filenames_20_09\n",
    "        elif rect['lat_min'] < -10 and rect['lon_max'] < 20:\n",
    "            dates_modis = np.array(dates_modis_19_10)\n",
    "            dates_modis_dt = np.array(dates_modis_datetime_19_10)\n",
    "            all_filenames = all_filenames_19_10\n",
    "        elif rect['lat_min'] < -10 and rect['lon_max'] > 20:\n",
    "            dates_modis = np.array(dates_modis_20_10)\n",
    "            dates_modis_dt = np.array(dates_modis_datetime_20_10)\n",
    "            all_filenames = all_filenames_20_10\n",
    "\n",
    "        #beginning date\n",
    "        date_start = datetime.strptime(firedate['idatestr'],\"%Y-%m-%d\").date()\n",
    "        date_modis_start = nearest_before(dates_modis_dt, date_start)\n",
    "        print('Start date: ' + str(date_start))\n",
    "        print('Modis start date: '+ str(date_modis_start))\n",
    "\n",
    "        #end date\n",
    "        date_end = datetime.strptime(firedate['fdatestr'],\"%Y-%m-%d\").date()\n",
    "        date_modis_end = nearest_after(dates_modis_dt, date_end)\n",
    "        print('End date: ' + str(date_end))\n",
    "        print('Modis end date: ' + str(date_modis_end))\n",
    "\n",
    "        #load images\n",
    "        print('Loading images')\n",
    "        start_filename = all_filenames[np.argwhere(dates_modis==date_modis_start)[0][0]]\n",
    "        end_filename = all_filenames[np.argwhere(dates_modis==date_modis_end)[0][0]]\n",
    "\n",
    "        modis_pre  = rxr.open_rasterio(start_filename, masked = True)\n",
    "        modis_post = rxr.open_rasterio(end_filename, masked = True)     \n",
    "\n",
    "        modis_lon_min_pre, modis_lon_max_pre, modis_lat_min_pre, modis_lat_max_pre, modis_lon_jump_pre, modis_lat_jump_pre = get_modis_latitude_longitude(modis_pre)\n",
    "        modis_lon_min_post, modis_lon_max_post, modis_lat_min_post, modis_lat_max_post, modis_lon_jump_post, modis_lat_jump_post = get_modis_latitude_longitude(modis_post)\n",
    "\n",
    "        data_pre_R, data_pre_NIR, data_pre_SWIR = preprocess_data(modis_pre)\n",
    "        data_post_R, data_post_NIR, data_post_SWIR = preprocess_data(modis_post)\n",
    "\n",
    "        print('show images')\n",
    "        showSCL(data_pre_R)\n",
    "        showSCL(data_post_R)\n",
    "        showSCL(data_pre_NIR)\n",
    "        showSCL(data_post_NIR)\n",
    "\n",
    "        #cloud masks\n",
    "        print('making masks')\n",
    "        pre_SCL_Mask_R   = computeSCLMask(data_pre_R)\n",
    "        pre_SCL_Mask_NIR = computeSCLMask(data_pre_NIR)\n",
    "\n",
    "        post_SCL_Mask_R   = computeSCLMask(data_post_R)\n",
    "        post_SCL_Mask_NIR = computeSCLMask(data_post_NIR)\n",
    "\n",
    "        pre_SCL_Mask_SWIR  = computeSCLMask(data_pre_SWIR)\n",
    "        post_SCL_Mask_SWIR = computeSCLMask(data_post_SWIR)\n",
    "\n",
    "        #NDVI\n",
    "        print('calculating NDVI')\n",
    "        ndvi_pre  = computeNDVI(data_pre_R,  data_pre_NIR,  pre_SCL_Mask_R,  pre_SCL_Mask_NIR)\n",
    "        ndvi_post = computeNDVI(data_post_R, data_post_NIR, post_SCL_Mask_R, post_SCL_Mask_NIR)\n",
    "        dNDVI = ndvi_pre - ndvi_post\n",
    "\n",
    "        print('remapping NDVI')\n",
    "        ndvi_pre_remapped_f = remapNDVI(ndvi_pre) #select rectangle\n",
    "        ndvi_post_remapped_f = remapNDVI(ndvi_post)\n",
    "        dndvi_remapped_f = remapNDVI(dNDVI)\n",
    "\n",
    "        print('show NDVI')\n",
    "        showNDVI(ndvi_pre_remapped_f)\n",
    "        showNDVI(ndvi_post_remapped_f)\n",
    "        showNDVI(dndvi_remapped_f)\n",
    "\n",
    "        #DNBR\n",
    "        print('calculate dnbr')\n",
    "        dnbr = computeFireMasks(data_pre_NIR, data_pre_SWIR, data_post_NIR, data_post_SWIR)\n",
    "        remapped_dnbr = remapDNBR(dnbr)\n",
    "\n",
    "        print('show dnbr')\n",
    "        showDNBR(dnbr) #remap function is within this\n",
    "\n",
    "        #get fire rectangle\n",
    "        print('get fire rectangle')\n",
    "        index_lon_min_pre, index_lon_max_pre, index_lat_min_pre, index_lat_max_pre = fire_rect_indices(modis_lon_min_pre,\n",
    "                                                                                       modis_lon_jump_pre,\n",
    "                                                                                       modis_lat_max_pre,\n",
    "                                                                                       modis_lat_jump_pre,\n",
    "                                                                                       rect)\n",
    "        index_lon_min_post, index_lon_max_post, index_lat_min_post, index_lat_max_post = fire_rect_indices(modis_lon_min_post,\n",
    "                                                                                       modis_lon_jump_post,\n",
    "                                                                                       modis_lat_max_post,\n",
    "                                                                                       modis_lat_jump_post,\n",
    "                                                                                       rect)\n",
    "\n",
    "\n",
    "        #avg over pre and post\n",
    "        avg_idx_lon_min = round(np.mean([index_lon_min_pre,index_lon_min_post]))\n",
    "        avg_idx_lon_max = round(np.mean([index_lon_max_pre,index_lon_max_post]))\n",
    "        avg_idx_lat_min = round(np.mean([index_lat_min_pre,index_lat_min_post]))\n",
    "        avg_idx_lat_max = round(np.mean([index_lat_max_pre,index_lat_max_post]))\n",
    "\n",
    "        #get ndvi and dnbr only for fire rectangle\n",
    "        rect_ndvi_pre = ndvi_pre_remapped_f[index_lat_max_pre:index_lat_min_pre+1,index_lon_min_pre:index_lon_max_pre+1]\n",
    "        rect_ndvi_post = ndvi_post_remapped_f[index_lat_max_post:index_lat_min_post+1,index_lon_min_post:index_lon_max_post+1]\n",
    "        rect_dndvi = dndvi_remapped_f[avg_idx_lat_max:avg_idx_lat_min+1,avg_idx_lon_min:avg_idx_lon_max+1]\n",
    "        rect_dnbr = remapped_dnbr[avg_idx_lat_max:avg_idx_lat_min+1,avg_idx_lon_min:avg_idx_lon_max+1]\n",
    "        \n",
    "        #nonremapped\n",
    "        rect_ndvi_pre_og = ndvi_pre[index_lat_max_pre:index_lat_min_pre+1,index_lon_min_pre:index_lon_max_pre+1]\n",
    "        rect_dnbr_og = dnbr[avg_idx_lat_max:avg_idx_lat_min+1,avg_idx_lon_min:avg_idx_lon_max+1]\n",
    "    \n",
    "        #append \n",
    "        ndvi_pre_remapped.append(np.nanmean(rect_ndvi_pre))  \n",
    "        ndvi_post_remapped.append(np.nanmean(rect_ndvi_post))     \n",
    "        dndvi_remapped.append(np.nanmean(rect_dndvi))          \n",
    "        dnbr_remapped.append(np.nanmean(rect_dnbr))\n",
    "        \n",
    "        #nonremapped\n",
    "        ndvi_pre_og.append(np.nanmean(rect_ndvi_pre_og))\n",
    "        dnbr_og.append(np.nanmean(rect_dnbr_og))\n",
    "\n",
    "        #save - keep rewriting at every iteration\n",
    "        np.save('ndvi_pre_remapped_largest_fires_redone_{}'.format(vegetation),ndvi_pre_remapped)\n",
    "        np.save('ndvi_post_remapped_largest_fires_redone_{}'.format(vegetation),ndvi_post_remapped)\n",
    "        np.save('dndvi_remapped_largest_fires_redone_{}'.format(vegetation),dndvi_remapped)\n",
    "        np.save('dnbr_remapped_largest_fires_redone_{}'.format(vegetation),dnbr_remapped)\n",
    "        np.save('ndvi_pre_og_largest_fires_redone_{}'.format(vegetation),ndvi_pre_og)\n",
    "        np.save('dnbr_og_largest_fires_redone_{}'.format(vegetation),dnbr_og)\n",
    "        \n",
    "        #if wanted, can save the images (NDVI/DNBR)\n",
    "        if j == save_fire_index:\n",
    "            filename_ndvi = 'ndvi_pre_remapped.png'\n",
    "            save_NDVI(ndvi_pre_remapped,filename_ndvi,modis_lon_min_pre,modis_lon_max_pre,modis_lat_min_pre,modis_lat_max_pre)\n",
    "            filename_dnbr = 'dnbr_remapped.png'\n",
    "            save_DNBR(dnbr,filename_dnbr,modis_lon_min_pre,modis_lon_max_pre,modis_lat_min_pre,modis_lat_max_pre)\n",
    "            \n",
    "        print('end of loop')\n",
    "        del modis_pre\n",
    "        del modis_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa846f-ea32-485b-97d0-e20e52a50bda",
   "metadata": {
    "tags": []
   },
   "source": [
    "-------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
